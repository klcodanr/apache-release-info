{
  "id": "12329486",
  "name": "1.3.1",
  "description": "",
  "date": "2015-04-17",
  "version": "1.3.1",
  "module": "",
  "lastUpdated": 1633104420547,
  "type": "release",
  "_links": {
    "self": {
      "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
    },
    "jira": {
      "href": "https://issues.apache.org/jira/browse/SPARK/fixforversion/12329486"
    },
    "project": {
      "href": "https://apis.danklco.com/apache-release-info/SPARK"
    }
  },
  "releaseNotes": "Release Notes - Spark - Version 1.3.1",
  "_embedded": {
    "issues": [
      {
        "issue": "SPARK-6117",
        "title": "describe function for summary statistics",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6117"
          }
        }
      },
      {
        "issue": "SPARK-6119",
        "title": "DataFrame.dropna support",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6119"
          }
        }
      },
      {
        "issue": "SPARK-6554",
        "title": "Cannot use partition columns in where clause when Parquet filter push-down is enabled",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6554"
          }
        }
      },
      {
        "issue": "SPARK-6563",
        "title": "DataFrame.fillna",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6563"
          }
        }
      },
      {
        "issue": "SPARK-6564",
        "title": "SQLContext.emptyDataFrame should contain 0 rows, not 1 row",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6564"
          }
        }
      },
      {
        "issue": "SPARK-6603",
        "title": "SQLContext.registerFunction -> SQLContext.udf.register",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6603"
          }
        }
      },
      {
        "issue": "SPARK-6623",
        "title": "Alias DataFrame.na.fill/drop in Python",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6623"
          }
        }
      },
      {
        "issue": "SPARK-6625",
        "title": "Add common string filters to data sources",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6625"
          }
        }
      },
      {
        "issue": "SPARK-3266",
        "title": "JavaDoubleRDD doesn't contain max()",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-3266"
          }
        }
      },
      {
        "issue": "SPARK-3570",
        "title": "Shuffle write time does not include time to open shuffle files",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-3570"
          }
        }
      },
      {
        "issue": "SPARK-4044",
        "title": "Thriftserver fails to start when JAVA_HOME points to JRE instead of JDK",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-4044"
          }
        }
      },
      {
        "issue": "SPARK-4300",
        "title": "Race condition during SparkWorker shutdown",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-4300"
          }
        }
      },
      {
        "issue": "SPARK-4704",
        "title": "SparkSubmitDriverBootstrap doesn't flush output",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-4704"
          }
        }
      },
      {
        "issue": "SPARK-5320",
        "title": "Joins on simple table created using select gives error",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-5320"
          }
        }
      },
      {
        "issue": "SPARK-5371",
        "title": "Failure to analyze query with UNION ALL and double aggregation",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-5371"
          }
        }
      },
      {
        "issue": "SPARK-5680",
        "title": "Sum function on all null values, should return zero",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-5680"
          }
        }
      },
      {
        "issue": "SPARK-5821",
        "title": "JSONRelation and ParquetRelation2 should check if delete is successful for the overwrite operation.",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-5821"
          }
        }
      },
      {
        "issue": "SPARK-6036",
        "title": "EventLog process logic has race condition with Akka actor system",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6036"
          }
        }
      },
      {
        "issue": "SPARK-6054",
        "title": "SQL UDF returning object of case class; regression from 1.2.0",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6054"
          }
        }
      },
      {
        "issue": "SPARK-6063",
        "title": "MLlib doesn't pass mvn scalastyle check due to UTF chars in LDAModel.scala",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6063"
          }
        }
      },
      {
        "issue": "SPARK-6077",
        "title": "Multiple spark streaming tabs on UI when reuse the same sparkcontext",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6077"
          }
        }
      },
      {
        "issue": "SPARK-6088",
        "title": "UI is malformed when tasks fetch remote results",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6088"
          }
        }
      },
      {
        "issue": "SPARK-6132",
        "title": "Context cleaner race condition across SparkContexts",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6132"
          }
        }
      },
      {
        "issue": "SPARK-6133",
        "title": "SparkContext#stop is not idempotent",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6133"
          }
        }
      },
      {
        "issue": "SPARK-6145",
        "title": "ORDER BY fails to resolve nested fields",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6145"
          }
        }
      },
      {
        "issue": "SPARK-6194",
        "title": "collect() in PySpark will cause memory leak in JVM",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6194"
          }
        }
      },
      {
        "issue": "SPARK-6209",
        "title": "ExecutorClassLoader can leak connections after failing to load classes from the REPL class server",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6209"
          }
        }
      },
      {
        "issue": "SPARK-6210",
        "title": "Generated column name should not include id of column in it.",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6210"
          }
        }
      },
      {
        "issue": "SPARK-6222",
        "title": "[STREAMING] All data may not be recovered from WAL when driver is killed",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6222"
          }
        }
      },
      {
        "issue": "SPARK-6245",
        "title": "jsonRDD() of empty RDD results in exception",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6245"
          }
        }
      },
      {
        "issue": "SPARK-6247",
        "title": "Certain self joins cannot be analyzed",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6247"
          }
        }
      },
      {
        "issue": "SPARK-6248",
        "title": "LocalRelation needs to implement statistics",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6248"
          }
        }
      },
      {
        "issue": "SPARK-6250",
        "title": "Types are now reserved words in DDL parser.",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6250"
          }
        }
      },
      {
        "issue": "SPARK-6286",
        "title": "Handle TASK_ERROR in TaskState",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6286"
          }
        }
      },
      {
        "issue": "SPARK-6294",
        "title": "PySpark task may hang while call take() on in Java/Scala",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6294"
          }
        }
      },
      {
        "issue": "SPARK-6299",
        "title": "ClassNotFoundException in standalone mode when running groupByKey with class defined in REPL.",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6299"
          }
        }
      },
      {
        "issue": "SPARK-6300",
        "title": "sc.addFile(path) does not support the relative path.",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6300"
          }
        }
      },
      {
        "issue": "SPARK-6313",
        "title": "Fetch File Lock file creation doesnt work when Spark working dir is on a NFS mount",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6313"
          }
        }
      },
      {
        "issue": "SPARK-6315",
        "title": "SparkSQL 1.3.0 (RC3) fails to read parquet file generated by 1.1.1",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6315"
          }
        }
      },
      {
        "issue": "SPARK-6325",
        "title": "YarnAllocator crash with dynamic allocation on",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6325"
          }
        }
      },
      {
        "issue": "SPARK-6330",
        "title": "newParquetRelation gets incorrect FileSystem",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6330"
          }
        }
      },
      {
        "issue": "SPARK-6337",
        "title": "Spark 1.3 doc fixes",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6337"
          }
        }
      },
      {
        "issue": "SPARK-6345",
        "title": "Model update propagation during prediction in Streaming Regression",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6345"
          }
        }
      },
      {
        "issue": "SPARK-6351",
        "title": "ParquetRelation2 does not support paths for different file systems",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6351"
          }
        }
      },
      {
        "issue": "SPARK-6365",
        "title": "jetty-security needed for SPARK_PREPEND_CLASSES to work",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6365"
          }
        }
      },
      {
        "issue": "SPARK-6366",
        "title": "In Python API, the default save mode for save and saveAsTable should be \"error\" instead of \"append\".",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6366"
          }
        }
      },
      {
        "issue": "SPARK-6369",
        "title": "InsertIntoHiveTable and Parquet Relation should use logic from SparkHadoopWriter",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6369"
          }
        }
      },
      {
        "issue": "SPARK-6375",
        "title": "Bad formatting in analysis errors",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6375"
          }
        }
      },
      {
        "issue": "SPARK-6376",
        "title": "Subqueries are thrown away too early in dataframes",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6376"
          }
        }
      },
      {
        "issue": "SPARK-6383",
        "title": "Few examples on Dataframe operation give compiler errors",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6383"
          }
        }
      },
      {
        "issue": "SPARK-6408",
        "title": "JDBCRDD fails on where clause with string literal",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6408"
          }
        }
      },
      {
        "issue": "SPARK-6409",
        "title": "It is not necessary that avoid old inteface of hive, because this will make some UDAF can not work.",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6409"
          }
        }
      },
      {
        "issue": "SPARK-6414",
        "title": "Spark driver failed with NPE on job cancelation",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6414"
          }
        }
      },
      {
        "issue": "SPARK-6421",
        "title": "_regression_train_wrapper does not test initialWeights correctly",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6421"
          }
        }
      },
      {
        "issue": "SPARK-6437",
        "title": "SQL ExternalSort should use CompletionIterator to clean up temp files",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6437"
          }
        }
      },
      {
        "issue": "SPARK-6450",
        "title": "Metastore Parquet table conversion fails when a single metastore Parquet table appears multiple times in the query",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6450"
          }
        }
      },
      {
        "issue": "SPARK-6452",
        "title": "CheckAnalysis should throw when the Aggregate node contains missing input attribute(s)",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6452"
          }
        }
      },
      {
        "issue": "SPARK-6454",
        "title": "Fix several broken links in PySpark docs",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6454"
          }
        }
      },
      {
        "issue": "SPARK-6457",
        "title": "Error when calling Pyspark RandomForestModel.load",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6457"
          }
        }
      },
      {
        "issue": "SPARK-6458",
        "title": "Bad error message for invalid data sources",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6458"
          }
        }
      },
      {
        "issue": "SPARK-6463",
        "title": "AttributeSet.equal should compare size",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6463"
          }
        }
      },
      {
        "issue": "SPARK-6465",
        "title": "GenericRowWithSchema: KryoException: Class cannot be created (missing no-arg constructor):",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6465"
          }
        }
      },
      {
        "issue": "SPARK-6480",
        "title": "histogram() bucket function is wrong in some simple edge cases",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6480"
          }
        }
      },
      {
        "issue": "SPARK-6491",
        "title": "Spark will put the current working dir to the CLASSPATH",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6491"
          }
        }
      },
      {
        "issue": "SPARK-6496",
        "title": "Multinomial Logistic Regression failed when initialWeights is not null",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6496"
          }
        }
      },
      {
        "issue": "SPARK-6504",
        "title": "Cannot read Parquet files generated from different versions at once",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6504"
          }
        }
      },
      {
        "issue": "SPARK-6538",
        "title": "Add missing nullable Metastore fields when merging a Parquet schema",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6538"
          }
        }
      },
      {
        "issue": "SPARK-6544",
        "title": "Problem with Avro and Kryo Serialization",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6544"
          }
        }
      },
      {
        "issue": "SPARK-6550",
        "title": "Add PreAnalyzer to keep logical plan consistent across DataFrame",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6550"
          }
        }
      },
      {
        "issue": "SPARK-6555",
        "title": "Override equals and hashCode in MetastoreRelation",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6555"
          }
        }
      },
      {
        "issue": "SPARK-6558",
        "title": "Utils.getCurrentUserName returns the full principal name instead of login name",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6558"
          }
        }
      },
      {
        "issue": "SPARK-6571",
        "title": "MatrixFactorizationModel created by load fails on predictAll",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6571"
          }
        }
      },
      {
        "issue": "SPARK-6574",
        "title": "Python Example sql.py not working in version 1.3",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6574"
          }
        }
      },
      {
        "issue": "SPARK-6575",
        "title": "Converted Parquet Metastore tables no longer cache metadata",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6575"
          }
        }
      },
      {
        "issue": "SPARK-6578",
        "title": "Outbound channel in network library is not thread-safe, can lead to fetch failures",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6578"
          }
        }
      },
      {
        "issue": "SPARK-6592",
        "title": "API of Row trait should be presented in Scala doc",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6592"
          }
        }
      },
      {
        "issue": "SPARK-6614",
        "title": "OutputCommitCoordinator should clear authorized committers only after authorized committer fails, not after any failure",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6614"
          }
        }
      },
      {
        "issue": "SPARK-6621",
        "title": "Calling EventLoop.stop in EventLoop.onReceive and EventLoop.onError should call onStop",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6621"
          }
        }
      },
      {
        "issue": "SPARK-6633",
        "title": "Should be \"Contains\" instead of \"EndsWith\" when constructing sources.StringContains",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6633"
          }
        }
      },
      {
        "issue": "SPARK-6642",
        "title": "Change the lambda weight to number of explicit ratings in implicit ALS",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6642"
          }
        }
      },
      {
        "issue": "SPARK-6650",
        "title": "ExecutorAllocationManager never stops",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6650"
          }
        }
      },
      {
        "issue": "SPARK-6655",
        "title": "We need to read the schema of a data source table stored in spark.sql.sources.schema property",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6655"
          }
        }
      },
      {
        "issue": "SPARK-6660",
        "title": "MLLibPythonAPI.pythonToJava doesn't recognize object arrays",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6660"
          }
        }
      },
      {
        "issue": "SPARK-6667",
        "title": "hang while collect in PySpark",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6667"
          }
        }
      },
      {
        "issue": "SPARK-6669",
        "title": "Lock metastore client in analyzeTable",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6669"
          }
        }
      },
      {
        "issue": "SPARK-6670",
        "title": "HiveContext.analyze should throw UnsupportedOperationException instead of NotImplementedError",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6670"
          }
        }
      },
      {
        "issue": "SPARK-6672",
        "title": "createDataFrame from RDD[Row] with UDTs cannot be saved",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6672"
          }
        }
      },
      {
        "issue": "SPARK-6677",
        "title": "pyspark.sql nondeterministic issue with row fields",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6677"
          }
        }
      },
      {
        "issue": "SPARK-6686",
        "title": "toDF column rename does not work when columns contain '.'",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6686"
          }
        }
      },
      {
        "issue": "SPARK-6688",
        "title": "EventLoggingListener should always operate on resolved URIs",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6688"
          }
        }
      },
      {
        "issue": "SPARK-6737",
        "title": "OutputCommitCoordinator.authorizedCommittersByStage map out of memory",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6737"
          }
        }
      },
      {
        "issue": "SPARK-6800",
        "title": "Reading from JDBC with SQLContext, using lower/upper bounds and numPartitions gives incorrect results.",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6800"
          }
        }
      },
      {
        "issue": "SPARK-6851",
        "title": "Wrong answers for self joins of converted parquet relations",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6851"
          }
        }
      },
      {
        "issue": "SPARK-6937",
        "title": "Tiny bug in PowerIterationClusteringExample in which radius not accepted from command line",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6937"
          }
        }
      },
      {
        "issue": "SPARK-6950",
        "title": "Spark master UI believes some applications are in progress when they are actually completed",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6950"
          }
        }
      },
      {
        "issue": "SPARK-8296",
        "title": "Not able to load Dataframe using Python throws py4j.protocol.Py4JJavaError",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-8296"
          }
        }
      },
      {
        "issue": "SPARK-4985",
        "title": "Parquet support for date type",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-4985"
          }
        }
      },
      {
        "issue": "SPARK-5955",
        "title": "Add checkpointInterval to ALS",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-5955"
          }
        }
      },
      {
        "issue": "SPARK-6651",
        "title": "Delegate dense vector arithmetics to the underly numpy array",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6651"
          }
        }
      },
      {
        "issue": "SPARK-677",
        "title": "PySpark should not collect results through local filesystem",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-677"
          }
        }
      },
      {
        "issue": "SPARK-3441",
        "title": "Explain in docs that repartitionAndSortWithinPartitions enacts Hadoop style shuffle",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-3441"
          }
        }
      },
      {
        "issue": "SPARK-3619",
        "title": "Upgrade to Mesos 0.21 to work around MESOS-1688",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-3619"
          }
        }
      },
      {
        "issue": "SPARK-4925",
        "title": "Publish Spark SQL hive-thriftserver maven artifact",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-4925"
          }
        }
      },
      {
        "issue": "SPARK-5559",
        "title": "Flaky test: o.a.s.streaming.flume.FlumeStreamSuite",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-5559"
          }
        }
      },
      {
        "issue": "SPARK-5750",
        "title": "Document that ordering of elements in shuffled partitions is not deterministic across runs",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-5750"
          }
        }
      },
      {
        "issue": "SPARK-5836",
        "title": "Highlight in Spark documentation that by default Spark does not delete its temporary files",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-5836"
          }
        }
      },
      {
        "issue": "SPARK-5911",
        "title": "Make Column.cast(to: String) support fixed precision and scale decimal type",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-5911"
          }
        }
      },
      {
        "issue": "SPARK-6079",
        "title": "Use index to speed up StatusTracker.getJobIdsForGroup()",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6079"
          }
        }
      },
      {
        "issue": "SPARK-6087",
        "title": "Provide actionable exception if Kryo buffer is not large enough",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6087"
          }
        }
      },
      {
        "issue": "SPARK-6124",
        "title": "Support jdbc connection properties in OPTIONS part of the query",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6124"
          }
        }
      },
      {
        "issue": "SPARK-6146",
        "title": "Support more datatype in SqlParser",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6146"
          }
        }
      },
      {
        "issue": "SPARK-6180",
        "title": "Error logged into log4j when use the HiveMetastoreCatalog::tableExists",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6180"
          }
        }
      },
      {
        "issue": "SPARK-6253",
        "title": "Add LassoModel to __all__ in regression.py",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6253"
          }
        }
      },
      {
        "issue": "SPARK-6274",
        "title": "Add streaming examples showing integration with DataFrames and SQL",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6274"
          }
        }
      },
      {
        "issue": "SPARK-6341",
        "title": "Upgrade breeze from 0.11.1 to 0.11.2 or later",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6341"
          }
        }
      },
      {
        "issue": "SPARK-6397",
        "title": "Exclude virtual columns from QueryPlan.missingInput",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6397"
          }
        }
      },
      {
        "issue": "SPARK-6459",
        "title": "Warn when Column API is constructing trivially true equality",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6459"
          }
        }
      },
      {
        "issue": "SPARK-6471",
        "title": "Metastore schema should only be a subset of parquet schema to support dropping of columns using replace columns",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6471"
          }
        }
      },
      {
        "issue": "SPARK-6536",
        "title": "Add IN to python Column",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6536"
          }
        }
      },
      {
        "issue": "SPARK-6553",
        "title": "Support for functools.partial as UserDefinedFunction",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6553"
          }
        }
      },
      {
        "issue": "SPARK-6618",
        "title": "HiveMetastoreCatalog.lookupRelation should use fine-grained lock",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6618"
          }
        }
      },
      {
        "issue": "SPARK-18391",
        "title": "Openstack deployment scenarios",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-18391"
          }
        }
      },
      {
        "issue": "SPARK-7238",
        "title": "Upgrade protobuf-java (com.google.protobuf) version from 2.4.1 to 2.5.0",
        "type": "Dependency upgrade",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-7238"
          }
        }
      },
      {
        "issue": "SPARK-6275",
        "title": "Miss toDF() function in docs/sql-programming-guide.md",
        "type": "Documentation",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6275"
          }
        }
      },
      {
        "issue": "SPARK-6278",
        "title": "Mention the change of step size in the migration guide",
        "type": "Documentation",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6278"
          }
        }
      },
      {
        "issue": "SPARK-6336",
        "title": "LBFGS should document what convergenceTol means",
        "type": "Documentation",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6336"
          }
        }
      },
      {
        "issue": "SPARK-6469",
        "title": "Improving documentation on YARN local directories usage",
        "type": "Documentation",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6469"
          }
        }
      },
      {
        "issue": "SPARK-6626",
        "title": "TwitterUtils.createStream documentation error",
        "type": "Documentation",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6626"
          }
        }
      },
      {
        "issue": "SPARK-6863",
        "title": "Formatted list broken on Hive compatibility section of SQL programming guide",
        "type": "Documentation",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/SPARK/12329486"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/SPARK-6863"
          }
        }
      }
    ]
  }
}