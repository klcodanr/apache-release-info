{
  "id": "12350027",
  "name": "0.9.0",
  "description": "",
  "date": "2021-08-26",
  "version": "0.9.0",
  "module": "",
  "lastUpdated": 1633045958807,
  "type": "release",
  "_links": {
    "self": {
      "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
    },
    "jira": {
      "href": "https://issues.apache.org/jira/jira/browse/HUDI/fixforversion/12350027"
    },
    "project": {
      "href": "https://apis.danklco.com/apache-release-info/HUDI"
    }
  },
  "releaseNotes": "Release Notes - Apache Hudi - Version 0.9.0",
  "_embedded": {
    "issues": [
      {
        "issue": "HUDI-251",
        "title": "Add JDBC Source support for Hudi DeltaStreamer",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-251"
          }
        }
      },
      {
        "issue": "HUDI-393",
        "title": "Integrate with Azure Pipeline run the end to end tests",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-393"
          }
        }
      },
      {
        "issue": "HUDI-699",
        "title": "Add unit test for CompactionCommand",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-699"
          }
        }
      },
      {
        "issue": "HUDI-1010",
        "title": "Fix the memory leak for hudi-client unit tests",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1010"
          }
        }
      },
      {
        "issue": "HUDI-1047",
        "title": "Support asynchronize clustering in CoW mode",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1047"
          }
        }
      },
      {
        "issue": "HUDI-1048",
        "title": "Support Asynchronize clustering in MoR mode",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1048"
          }
        }
      },
      {
        "issue": "HUDI-1077",
        "title": "Integration tests to validate clustering",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1077"
          }
        }
      },
      {
        "issue": "HUDI-1104",
        "title": "Bulk insert Dataset - UserDefinedPartitioner",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1104"
          }
        }
      },
      {
        "issue": "HUDI-1105",
        "title": "Bulk insert dataset - Dedup",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1105"
          }
        }
      },
      {
        "issue": "HUDI-1106",
        "title": "Bulk insert dataset - Drop duplicates",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1106"
          }
        }
      },
      {
        "issue": "HUDI-1293",
        "title": "RFC-15: Track range metadata as a part of metadata table",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1293"
          }
        }
      },
      {
        "issue": "HUDI-1371",
        "title": "Support file listing using metadata for Spark DataSource and Spark SQL queries",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1371"
          }
        }
      },
      {
        "issue": "HUDI-1433",
        "title": "Flink engine support sync data to hive table",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1433"
          }
        }
      },
      {
        "issue": "HUDI-1468",
        "title": "incremental read support with clustering",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1468"
          }
        }
      },
      {
        "issue": "HUDI-1478",
        "title": "Introduce HoodieBloomIndex to hudi-java-client",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1478"
          }
        }
      },
      {
        "issue": "HUDI-1482",
        "title": "async clustering for spark streaming",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1482"
          }
        }
      },
      {
        "issue": "HUDI-1483",
        "title": "async clustering for deltastreamer",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1483"
          }
        }
      },
      {
        "issue": "HUDI-1577",
        "title": "Document that multi-writer cannot be used within the same write client",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1577"
          }
        }
      },
      {
        "issue": "HUDI-1649",
        "title": "Bugs with Metadata Table in 0.7 release",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1649"
          }
        }
      },
      {
        "issue": "HUDI-1659",
        "title": "Basic implementation Of Spark Sql Support",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1659"
          }
        }
      },
      {
        "issue": "HUDI-1674",
        "title": "add partition level delete DOC or example",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1674"
          }
        }
      },
      {
        "issue": "HUDI-1676",
        "title": "Support SQL with spark3",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1676"
          }
        }
      },
      {
        "issue": "HUDI-1776",
        "title": "Support AlterCommand For Hoodie",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1776"
          }
        }
      },
      {
        "issue": "HUDI-1810",
        "title": "Azure CI integration test failed for CLI tests",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1810"
          }
        }
      },
      {
        "issue": "HUDI-1811",
        "title": "Azure CI connection refused error when init HoodieRealtimeRecordReader",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1811"
          }
        }
      },
      {
        "issue": "HUDI-1826",
        "title": "Add ORC support in HoodieSnapshotExporter",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1826"
          }
        }
      },
      {
        "issue": "HUDI-1828",
        "title": "Ensure All Tests Pass with ORC format",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1828"
          }
        }
      },
      {
        "issue": "HUDI-1842",
        "title": "[SQL] Spark Sql Support For The Exists Hoodie Table",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1842"
          }
        }
      },
      {
        "issue": "HUDI-1860",
        "title": "Add INSERT_OVERWRITE support to DeltaStreamer",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1860"
          }
        }
      },
      {
        "issue": "HUDI-1861",
        "title": "Add SQL Query Builder Utility",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1861"
          }
        }
      },
      {
        "issue": "HUDI-1883",
        "title": "Support Truncate Table For Hoodie",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1883"
          }
        }
      },
      {
        "issue": "HUDI-1884",
        "title": "MergeInto Support Partial Update For COW",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1884"
          }
        }
      },
      {
        "issue": "HUDI-1897",
        "title": "Implement DeltaStreamer Source for AWS S3",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1897"
          }
        }
      },
      {
        "issue": "HUDI-1930",
        "title": "Bootstrap support configure KeyGenerator by type",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1930"
          }
        }
      },
      {
        "issue": "HUDI-1944",
        "title": "Support Hudi to read from Kafka Consumer Group Offset",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1944"
          }
        }
      },
      {
        "issue": "HUDI-1959",
        "title": "Add links to small file handling and clustering to the config section",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1959"
          }
        }
      },
      {
        "issue": "HUDI-1960",
        "title": "Add documentation to be able to disable parquet configs",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1960"
          }
        }
      },
      {
        "issue": "HUDI-2051",
        "title": "Enable Hive Sync When Spark Enable Hive Meta For Spark Sql",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2051"
          }
        }
      },
      {
        "issue": "HUDI-2063",
        "title": "[SQL] Add Doc For Spark Sql Integrates With Hudi",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2063"
          }
        }
      },
      {
        "issue": "HUDI-2149",
        "title": "Ensure documentation for every HoodieConfig/ConfigProperty",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2149"
          }
        }
      },
      {
        "issue": "HUDI-2161",
        "title": "Add support to disable meta column to BulkInsert Row Writer path",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2161"
          }
        }
      },
      {
        "issue": "HUDI-2176",
        "title": "Virutal keys support for COW all operations",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2176"
          }
        }
      },
      {
        "issue": "HUDI-2177",
        "title": "Virtual keys support for Compaction",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2177"
          }
        }
      },
      {
        "issue": "HUDI-2178",
        "title": "Virtual keys support for Clustering COW",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2178"
          }
        }
      },
      {
        "issue": "HUDI-2179",
        "title": "Virtual keys support for Metadata table COW",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2179"
          }
        }
      },
      {
        "issue": "HUDI-2182",
        "title": "Support Compaction Command For Spark Sql",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2182"
          }
        }
      },
      {
        "issue": "HUDI-2200",
        "title": "Virtual keys support for MOR table: realtime/snapshot read",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2200"
          }
        }
      },
      {
        "issue": "HUDI-2208",
        "title": "[SQL] Support Bulk Insert For Spark Sql",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2208"
          }
        }
      },
      {
        "issue": "HUDI-2212",
        "title": "Missing PrimaryKey In Hoodie Properties For CTAS Table",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2212"
          }
        }
      },
      {
        "issue": "HUDI-2221",
        "title": "[SQL] Functionality testing with Spark 2",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2221"
          }
        }
      },
      {
        "issue": "HUDI-2222",
        "title": "[SQL] Test catalog integration",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2222"
          }
        }
      },
      {
        "issue": "HUDI-2225",
        "title": "Add compaction example",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2225"
          }
        }
      },
      {
        "issue": "HUDI-2232",
        "title": "[SQL] MERGE INTO fails with table having nested struct",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2232"
          }
        }
      },
      {
        "issue": "HUDI-2233",
        "title": "[SQL] Hive sync is not working",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2233"
          }
        }
      },
      {
        "issue": "HUDI-2236",
        "title": "Add virtual key support to Clustering in MOR",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2236"
          }
        }
      },
      {
        "issue": "HUDI-2250",
        "title": "[SQL] Bulk insert support for tables w/ primary key",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2250"
          }
        }
      },
      {
        "issue": "HUDI-2251",
        "title": "[SQL] Fix Exception Cause By Table Name Case Sensitivity For Append Mode Write",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2251"
          }
        }
      },
      {
        "issue": "HUDI-2268",
        "title": "Upgrade hoodie table to 0.9.0",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2268"
          }
        }
      },
      {
        "issue": "HUDI-2282",
        "title": "Insert for an already existing record throws DuplicateKeyException with primary keyed spark sql table",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2282"
          }
        }
      },
      {
        "issue": "HUDI-2315",
        "title": "Maintain compatibility with pre Hudi 0.9.0 config keys, while marking them as deprecated",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2315"
          }
        }
      },
      {
        "issue": "HUDI-2317",
        "title": "Publish a blog on virtual keys",
        "type": "Sub-task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2317"
          }
        }
      },
      {
        "issue": "HUDI-774",
        "title": "Spark to Avro converter incorrectly generates optional fields",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-774"
          }
        }
      },
      {
        "issue": "HUDI-1007",
        "title": "When earliestOffsets is greater than checkpoint, Hudi will not be able to successfully consume data",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1007"
          }
        }
      },
      {
        "issue": "HUDI-1063",
        "title": "Save in Google Cloud Storage not working",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1063"
          }
        }
      },
      {
        "issue": "HUDI-1129",
        "title": "AvroConversionUtils unable to handle avro to row transformation when passing evolved schema",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1129"
          }
        }
      },
      {
        "issue": "HUDI-1175",
        "title": "Investigate CI test flakiness (hangs)",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1175"
          }
        }
      },
      {
        "issue": "HUDI-1592",
        "title": "Metadata listing fails for non partitoned dataset",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1592"
          }
        }
      },
      {
        "issue": "HUDI-1597",
        "title": "Maven build fail",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1597"
          }
        }
      },
      {
        "issue": "HUDI-1651",
        "title": "Fix archival of requested replace instants",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1651"
          }
        }
      },
      {
        "issue": "HUDI-1690",
        "title": "Fix StackOverflowError while running clustering with large number of partitions",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1690"
          }
        }
      },
      {
        "issue": "HUDI-1716",
        "title": "rt view w/ MOR tables fails after schema evolution",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1716"
          }
        }
      },
      {
        "issue": "HUDI-1717",
        "title": "Metadata Table reader does not show correct view of the metadata",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1717"
          }
        }
      },
      {
        "issue": "HUDI-1718",
        "title": "when query incr view of  mor table which has Multi level partitions, the query failed",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1718"
          }
        }
      },
      {
        "issue": "HUDI-1719",
        "title": "hive on spark/mr,Incremental query of the mor table, the partition field is incorrect",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1719"
          }
        }
      },
      {
        "issue": "HUDI-1720",
        "title": "when query incr view of  mor table which has many delete records use sparksql/hive-beeline,  StackOverflowError",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1720"
          }
        }
      },
      {
        "issue": "HUDI-1722",
        "title": "hive beeline/spark-sql  query specified field on mor table occur NPE",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1722"
          }
        }
      },
      {
        "issue": "HUDI-1723",
        "title": "DFSPathSelector skips files with the same modify date when read up to source limit",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1723"
          }
        }
      },
      {
        "issue": "HUDI-1735",
        "title": "hudi-examples missed MapredParquetInputFormat class",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1735"
          }
        }
      },
      {
        "issue": "HUDI-1740",
        "title": "insert_overwrite_table and insert_overwrite first replacecommit has empty partitionToReplaceFileIds",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1740"
          }
        }
      },
      {
        "issue": "HUDI-1744",
        "title": "[Rollback] rollback fail on mor table when the partition path hasn't any files",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1744"
          }
        }
      },
      {
        "issue": "HUDI-1749",
        "title": "Clean/Compaction/Rollback command maybe never exit when operation fail",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1749"
          }
        }
      },
      {
        "issue": "HUDI-1750",
        "title": "Fail to load user's class if user move hudi-spark-bundle_2.11-0.7.0.jar into spark classpath",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1750"
          }
        }
      },
      {
        "issue": "HUDI-1772",
        "title": "HoodieFileGroupId compareTo logical error(fileId self compare)",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1772"
          }
        }
      },
      {
        "issue": "HUDI-1781",
        "title": "Flink streaming reader throws ClassCastException when reading from empty table path",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1781"
          }
        }
      },
      {
        "issue": "HUDI-1783",
        "title": "Support Huawei  Cloud Object Storage",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1783"
          }
        }
      },
      {
        "issue": "HUDI-1792",
        "title": "flink-client  query error when processing files larger than 128mb",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1792"
          }
        }
      },
      {
        "issue": "HUDI-1798",
        "title": "Flink streaming reader should always monitor the delta commits files",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1798"
          }
        }
      },
      {
        "issue": "HUDI-1800",
        "title": "Incorrect HoodieTableFileSystem API usage for pending slices causing issues",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1800"
          }
        }
      },
      {
        "issue": "HUDI-1801",
        "title": "FlinkMergeHandle rolling over may miss to rename the latest file handle",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1801"
          }
        }
      },
      {
        "issue": "HUDI-1802",
        "title": "Timeline Server Bundle need to include com.esotericsoftware package",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1802"
          }
        }
      },
      {
        "issue": "HUDI-1804",
        "title": "Continue to write when Flink write task restart because of container killing",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1804"
          }
        }
      },
      {
        "issue": "HUDI-1805",
        "title": "Honor \"skipROSuffix\" in spark ds",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1805"
          }
        }
      },
      {
        "issue": "HUDI-1806",
        "title": "Honor \"skipROSuffix\" in spark ds",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1806"
          }
        }
      },
      {
        "issue": "HUDI-1809",
        "title": "Flink merge on read input split uses wrong base file path for default merge type",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1809"
          }
        }
      },
      {
        "issue": "HUDI-1817",
        "title": "when query incr view of hudi table by using spark-sql. the result is wrong",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1817"
          }
        }
      },
      {
        "issue": "HUDI-1835",
        "title": "Fix kafka native config name for auto reset offset",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1835"
          }
        }
      },
      {
        "issue": "HUDI-1845",
        "title": "Exception Throws When Sync Non-Partitioned Table To Hive With  MultiPartKeysValueExtractor",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1845"
          }
        }
      },
      {
        "issue": "HUDI-1858",
        "title": "Unable to create table due to jar conflict",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1858"
          }
        }
      },
      {
        "issue": "HUDI-1871",
        "title": "Fix hive conf for Flink writer hive meta sync",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1871"
          }
        }
      },
      {
        "issue": "HUDI-1873",
        "title": "collect() call causing issues with very large upserts",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1873"
          }
        }
      },
      {
        "issue": "HUDI-1888",
        "title": "Fix NPE in `RowKeyGenertorHelper#getNestedFieldVal` when row writer is enabled",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1888"
          }
        }
      },
      {
        "issue": "HUDI-1890",
        "title": "FlinkCreateHandle and FlinkAppendHandle canWrite should always return true",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1890"
          }
        }
      },
      {
        "issue": "HUDI-1893",
        "title": "HoodieFileIndex get a error when there is no partition path in table storage",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1893"
          }
        }
      },
      {
        "issue": "HUDI-1901",
        "title": "Not an Avro data file during archive",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1901"
          }
        }
      },
      {
        "issue": "HUDI-1915",
        "title": "Fix the file id for write data buffer before flushing",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1915"
          }
        }
      },
      {
        "issue": "HUDI-1917",
        "title": "Remove the metadata sync logic in HoodieFlinkWriteClient#preWrite because it is not thread safe",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1917"
          }
        }
      },
      {
        "issue": "HUDI-1918",
        "title": "Incorrect keyby field would cause serious data skew",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1918"
          }
        }
      },
      {
        "issue": "HUDI-1919",
        "title": "Type mismatch when streaming read copy_on_write table using flink",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1919"
          }
        }
      },
      {
        "issue": "HUDI-1922",
        "title": "bulk insert with row writer supports mor table",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1922"
          }
        }
      },
      {
        "issue": "HUDI-1942",
        "title": "HIVE_AUTO_CREATE_DATABASE_OPT_KEY This should default to true when Hudi synchronizes Hive",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1942"
          }
        }
      },
      {
        "issue": "HUDI-1943",
        "title": "Lose properties when hoodieWriteConfig initializtion",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1943"
          }
        }
      },
      {
        "issue": "HUDI-1950",
        "title": "Azure CI unit tests fail with connection refused",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1950"
          }
        }
      },
      {
        "issue": "HUDI-1953",
        "title": "No set the output type of the operator, Throw java.lang.NullPointerException",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1953"
          }
        }
      },
      {
        "issue": "HUDI-1957",
        "title": "Fix flink timeline service lack jetty dependency",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1957"
          }
        }
      },
      {
        "issue": "HUDI-1967",
        "title": "Fix the NPE for MOR Hive  rt table query",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1967"
          }
        }
      },
      {
        "issue": "HUDI-1987",
        "title": "Fix non partition table hive meta sync for flink writer",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1987"
          }
        }
      },
      {
        "issue": "HUDI-1988",
        "title": "FinalizeWrite() been executed twice in AbstractHoodieWriteClient$commitstats",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1988"
          }
        }
      },
      {
        "issue": "HUDI-1996",
        "title": "When using SchemaRegistryProvider.java cant pass basic auth creds in url",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1996"
          }
        }
      },
      {
        "issue": "HUDI-1997",
        "title": "Fix hoodie.datasource.hive_sync.auto_create_database documentation",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1997"
          }
        }
      },
      {
        "issue": "HUDI-1999",
        "title": "Refresh the base file view cache for WriteProfile",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1999"
          }
        }
      },
      {
        "issue": "HUDI-2009",
        "title": "Fix extra commit metadata in row writer path",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2009"
          }
        }
      },
      {
        "issue": "HUDI-2013",
        "title": "Fallback to file listing may lead to data loss",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2013"
          }
        }
      },
      {
        "issue": "HUDI-2016",
        "title": "Metadata table bootstrap does not work when there are inflight instances",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2016"
          }
        }
      },
      {
        "issue": "HUDI-2017",
        "title": "Some of the Metadata table metrics are incorrect",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2017"
          }
        }
      },
      {
        "issue": "HUDI-2019",
        "title": "Update writeConfig in every client",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2019"
          }
        }
      },
      {
        "issue": "HUDI-2031",
        "title": "JVM occasionally crashes during compaction when spark speculative execution is enabled",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2031"
          }
        }
      },
      {
        "issue": "HUDI-2033",
        "title": "ClassCastException Throw When PreCombineField Is String Type",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2033"
          }
        }
      },
      {
        "issue": "HUDI-2043",
        "title": "HoodieDefaultTimeline$filterPendingCompactionTImeline() method have wrong filter condition",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2043"
          }
        }
      },
      {
        "issue": "HUDI-2046",
        "title": "Loaded too many classes when use kryo of spark to hudi",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2046"
          }
        }
      },
      {
        "issue": "HUDI-2049",
        "title": "StreamWriteFunction should wait for the  next inflight instant time before flushing",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2049"
          }
        }
      },
      {
        "issue": "HUDI-2053",
        "title": "Insert Static Partition With DateType Return Incorrect Partition Value",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2053"
          }
        }
      },
      {
        "issue": "HUDI-2057",
        "title": "CTAS Generate An External Table When Create Managed Table",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2057"
          }
        }
      },
      {
        "issue": "HUDI-2058",
        "title": "support incremental query for insert_overwrite_table/insert_overwrite operation on cow table",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2058"
          }
        }
      },
      {
        "issue": "HUDI-2061",
        "title": "Incorrect Schema Inference For Schema Evolved Table",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2061"
          }
        }
      },
      {
        "issue": "HUDI-2062",
        "title": "Catch FileNotFoundException in WriteProfiles #getCommitMetadataSafely",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2062"
          }
        }
      },
      {
        "issue": "HUDI-2064",
        "title": "Fix TestHoodieBackedMetadata#testOnlyValidPartitionsAdded",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2064"
          }
        }
      },
      {
        "issue": "HUDI-2066",
        "title": "Fix flaky test: HoodieSparkSqlWriterSuite.test schema evolution",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2066"
          }
        }
      },
      {
        "issue": "HUDI-2068",
        "title": "Skip the assign state for SmallFileAssign when the state can not assign initially",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2068"
          }
        }
      },
      {
        "issue": "HUDI-2069",
        "title": "Fix KafkaAvroSchemaDeserializer to not rely on reflection",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2069"
          }
        }
      },
      {
        "issue": "HUDI-2073",
        "title": "The sparkJob of hoodieClusteringJob running through sparkSubmit will not quit even it is finished or failed.",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2073"
          }
        }
      },
      {
        "issue": "HUDI-2088",
        "title": "Missing Partition Fields And PreCombineField In Hoodie Properties For Table Written By Flink",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2088"
          }
        }
      },
      {
        "issue": "HUDI-2089",
        "title": "fix the bug that metatable cannot support non_partition table",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2089"
          }
        }
      },
      {
        "issue": "HUDI-2090",
        "title": "when  hudi metadata is enabled,  use different user to query table, the query will failed",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2090"
          }
        }
      },
      {
        "issue": "HUDI-2092",
        "title": "Fix NPE caused by FlinkStreamerConfig#writePartitionUrlEncode null value",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2092"
          }
        }
      },
      {
        "issue": "HUDI-2093",
        "title": "Fix empty avro schema path caused by duplicate parameters",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2093"
          }
        }
      },
      {
        "issue": "HUDI-2097",
        "title": "Fix unable to read commit metadata error",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2097"
          }
        }
      },
      {
        "issue": "HUDI-2099",
        "title": " hive lock which state is WATING should be released,  otherwise this hive lock will be locked forever",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2099"
          }
        }
      },
      {
        "issue": "HUDI-2105",
        "title": "Compaction Failed For MergeInto MOR Table",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2105"
          }
        }
      },
      {
        "issue": "HUDI-2106",
        "title": "Fix flink batch compaction bug while user don't set compaction tasks",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2106"
          }
        }
      },
      {
        "issue": "HUDI-2107",
        "title": "Support Read Log Only MOR Table For Spark",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2107"
          }
        }
      },
      {
        "issue": "HUDI-2110",
        "title": "Fix FlinkOptions$URL_ENCODE_PARTITIONING optionBuilder error",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2110"
          }
        }
      },
      {
        "issue": "HUDI-2114",
        "title": "Spark Query MOR Table Written By Flink Return Incorrect Timestamp Value",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2114"
          }
        }
      },
      {
        "issue": "HUDI-2115",
        "title": "FileSlices in the filegroup is not descending by timestamp",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2115"
          }
        }
      },
      {
        "issue": "HUDI-2116",
        "title": " sync 10w partitions to hive by using HiveSyncTool lead to the oom of hive MetaStore",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2116"
          }
        }
      },
      {
        "issue": "HUDI-2119",
        "title": "Syncing of rollbacks to metadata table does not work in all cases",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2119"
          }
        }
      },
      {
        "issue": "HUDI-2123",
        "title": "Exception When Merge With Null-Value Field",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2123"
          }
        }
      },
      {
        "issue": "HUDI-2127",
        "title": "`maxMemorySizeInBytes` in log scanner is not initialized",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2127"
          }
        }
      },
      {
        "issue": "HUDI-2129",
        "title": "StreamerUtil.medianInstantTime should return a valid date time string",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2129"
          }
        }
      },
      {
        "issue": "HUDI-2131",
        "title": "Exception Throw Out When MergeInto With Decimal Type Field",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2131"
          }
        }
      },
      {
        "issue": "HUDI-2136",
        "title": "Fix packet conflict when flink-sql-connector-hive and hudi-flink-bundle both in flink lib",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2136"
          }
        }
      },
      {
        "issue": "HUDI-2139",
        "title": "MergeInto MOR Table May Result InCorrect Result",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2139"
          }
        }
      },
      {
        "issue": "HUDI-2140",
        "title": "Test failure : TestHoodieBackedMetadata.testOnlyValidPartitionsAdded",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2140"
          }
        }
      },
      {
        "issue": "HUDI-2144",
        "title": "Offline clustering(independent sparkJob) will cause insert action losing data",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2144"
          }
        }
      },
      {
        "issue": "HUDI-2146",
        "title": "Concurrent writes loss data",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2146"
          }
        }
      },
      {
        "issue": "HUDI-2153",
        "title": "BucketAssignFunction NullPointerException",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2153"
          }
        }
      },
      {
        "issue": "HUDI-2180",
        "title": "Fix Compile Error For Spark3",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2180"
          }
        }
      },
      {
        "issue": "HUDI-2195",
        "title": "Sync Hive Failed When Execute  CTAS In Spark2 And Spark3",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2195"
          }
        }
      },
      {
        "issue": "HUDI-2206",
        "title": "Fix checkpoint blocked  because getLastPendingInstant() action after than restoreWriteMetadata() action",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2206"
          }
        }
      },
      {
        "issue": "HUDI-2214",
        "title": "residual temporary files after clustering are not cleaned up",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2214"
          }
        }
      },
      {
        "issue": "HUDI-2217",
        "title": "Fix no value present in incremental query on MOR",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2217"
          }
        }
      },
      {
        "issue": "HUDI-2218",
        "title": "Fix missing HoodieWriteStat in HoodieCreateHandle",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2218"
          }
        }
      },
      {
        "issue": "HUDI-2219",
        "title": "Fix NPE of HoodieConfig",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2219"
          }
        }
      },
      {
        "issue": "HUDI-2223",
        "title": "Fix Alter Partitioned Table Failed",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2223"
          }
        }
      },
      {
        "issue": "HUDI-2227",
        "title": "Only sync hive meta on successful commit for flink batch writer",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2227"
          }
        }
      },
      {
        "issue": "HUDI-2230",
        "title": "\"Task not serializable\" exception due to non-serializable Codahale Timers",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2230"
          }
        }
      },
      {
        "issue": "HUDI-2243",
        "title": "Support Time Travel Query For Hoodie Table via DataSource",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2243"
          }
        }
      },
      {
        "issue": "HUDI-2244",
        "title": "Fix database alreadyExistsException while hive sync",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2244"
          }
        }
      },
      {
        "issue": "HUDI-2286",
        "title": "Handle the case of failed deltacommit on the metadata table.",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2286"
          }
        }
      },
      {
        "issue": "HUDI-2292",
        "title": "MOR not support predicate pushdown when reading with payload_combine type",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2292"
          }
        }
      },
      {
        "issue": "HUDI-2298",
        "title": "The HoodieMergedLogRecordScanner should set up the operation of the chosen record",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2298"
          }
        }
      },
      {
        "issue": "HUDI-2305",
        "title": "Fix marker-based rollback in 0.9.0",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2305"
          }
        }
      },
      {
        "issue": "HUDI-2307",
        "title": "When using delete_partition with ds should not rely on the primary key",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2307"
          }
        }
      },
      {
        "issue": "HUDI-2322",
        "title": "Only include meta fields to reorder while preparing dataset for bulk insert",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2322"
          }
        }
      },
      {
        "issue": "HUDI-2352",
        "title": "The upgrade downgrade action of flink writer should be singleton",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2352"
          }
        }
      },
      {
        "issue": "HUDI-2451",
        "title": "HoodieTableMetaClient The file separator from Window to HDFS is faulty",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2451"
          }
        }
      },
      {
        "issue": "HUDI-73",
        "title": "Support vanilla Avro Kafka Source in HoodieDeltaStreamer",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-73"
          }
        }
      },
      {
        "issue": "HUDI-944",
        "title": "Support more complete  concurrency control when writing data",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-944"
          }
        }
      },
      {
        "issue": "HUDI-1447",
        "title": "DeltaStreamer kafka source supports consuming from specified timestamp",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1447"
          }
        }
      },
      {
        "issue": "HUDI-1551",
        "title": "Support Partition with BigDecimal/Integer field for TimestampBasedKeyGenerator",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1551"
          }
        }
      },
      {
        "issue": "HUDI-1729",
        "title": "Asynchronous Hive sync and commits cleaning for Flink writer",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1729"
          }
        }
      },
      {
        "issue": "HUDI-1738",
        "title": "Emit deletes for Flink MOR table streaming read",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1738"
          }
        }
      },
      {
        "issue": "HUDI-1746",
        "title": "Added support for replace commits in hudi-cli",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1746"
          }
        }
      },
      {
        "issue": "HUDI-1771",
        "title": "Propagate CDC format for hoodie",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1771"
          }
        }
      },
      {
        "issue": "HUDI-1789",
        "title": "Support snapshot queries with maxInstantTimes",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1789"
          }
        }
      },
      {
        "issue": "HUDI-1814",
        "title": "Non partitioned table for Flink writer",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1814"
          }
        }
      },
      {
        "issue": "HUDI-1818",
        "title": "Validate and check required option for HoodieTable",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1818"
          }
        }
      },
      {
        "issue": "HUDI-1848",
        "title": "Add support for HMS in Hive-sync-tool",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1848"
          }
        }
      },
      {
        "issue": "HUDI-1852",
        "title": "Add SCHEMA_REGISTRY_SOURCE_URL_SUFFIX SCHEMA_REGISTRY_TARGET_URL_SUFFIX property",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1852"
          }
        }
      },
      {
        "issue": "HUDI-1946",
        "title": "Enhance SqlQueryBasedTransformer to allow user use wildcard to represent all the columns",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1946"
          }
        }
      },
      {
        "issue": "HUDI-2055",
        "title": "Add metric for time of lastSync",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2055"
          }
        }
      },
      {
        "issue": "HUDI-2070",
        "title": "Adding .asf.yaml file for web site publishing as per directives",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2070"
          }
        }
      },
      {
        "issue": "HUDI-2072",
        "title": "Add Precommit validator framework",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2072"
          }
        }
      },
      {
        "issue": "HUDI-2094",
        "title": "Supports hive style partitioning for flink writer",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2094"
          }
        }
      },
      {
        "issue": "HUDI-2165",
        "title": "Support Transformer for HoodieFlinkStreamer",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2165"
          }
        }
      },
      {
        "issue": "HUDI-2209",
        "title": "Bulk insert for flink writer",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2209"
          }
        }
      },
      {
        "issue": "HUDI-2258",
        "title": "Metadata table for flink",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2258"
          }
        }
      },
      {
        "issue": "HUDI-2269",
        "title": "Release the disk map resource for flink streaming reader",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2269"
          }
        }
      },
      {
        "issue": "HUDI-2274",
        "title": "Allows INSERT duplicates for Flink MOR table",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2274"
          }
        }
      },
      {
        "issue": "HUDI-89",
        "title": "Introduce a HoodieConfig/ConfigProperty framework to bring all configs under one roof",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-89"
          }
        }
      },
      {
        "issue": "HUDI-818",
        "title": "Optimize the default value of hoodie.memory.merge.max.size option",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-818"
          }
        }
      },
      {
        "issue": "HUDI-897",
        "title": "hudi support log append scenario with better write and asynchronous compaction",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-897"
          }
        }
      },
      {
        "issue": "HUDI-1138",
        "title": "Re-implement marker files via timeline server",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1138"
          }
        }
      },
      {
        "issue": "HUDI-1148",
        "title": "Revisit log messages seen when wiriting or reading through Hudi",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1148"
          }
        }
      },
      {
        "issue": "HUDI-1170",
        "title": "File Listing during log file rollback is affecting ingestion latency in S3",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1170"
          }
        }
      },
      {
        "issue": "HUDI-1241",
        "title": "Generate config docs automatically",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1241"
          }
        }
      },
      {
        "issue": "HUDI-1378",
        "title": "Add ENABLE_ROW_WRITER_OPT_KEY to Configurations (docs)",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1378"
          }
        }
      },
      {
        "issue": "HUDI-1415",
        "title": "Read Hoodie Table As Spark DataSource Table",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1415"
          }
        }
      },
      {
        "issue": "HUDI-1425",
        "title": "Performance loss with the additional hoodieRecords.isEmpty() in HoodieSparkSqlWriter#write",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1425"
          }
        }
      },
      {
        "issue": "HUDI-1426",
        "title": "Typo in class declaration",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1426"
          }
        }
      },
      {
        "issue": "HUDI-1446",
        "title": "Support skip bootstrapIndex's init in abstract fs view init",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1446"
          }
        }
      },
      {
        "issue": "HUDI-1453",
        "title": "Throw Exception when input data schema is not equal to the hoodie table schema",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1453"
          }
        }
      },
      {
        "issue": "HUDI-1548",
        "title": "Fix documentation around schema evolution",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1548"
          }
        }
      },
      {
        "issue": "HUDI-1560",
        "title": "How to deduce bloom filter configs",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1560"
          }
        }
      },
      {
        "issue": "HUDI-1591",
        "title": "Implement Spark's FileIndex for Hudi to support queries via Hudi DataSource using non-globbed table path and partition pruning",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1591"
          }
        }
      },
      {
        "issue": "HUDI-1620",
        "title": "TestPushGateWayReporter failed when run separately",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1620"
          }
        }
      },
      {
        "issue": "HUDI-1633",
        "title": "Make callback return HoodieWriteStat",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1633"
          }
        }
      },
      {
        "issue": "HUDI-1725",
        "title": "Remove AvroSchemaConverter since Flink 1.12.2 already provided",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1725"
          }
        }
      },
      {
        "issue": "HUDI-1726",
        "title": "Remove AvroSchemaConverter since Flink 1.12.2 already provided",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1726"
          }
        }
      },
      {
        "issue": "HUDI-1731",
        "title": "Rename UpsertPartitioner in both hudi-java-client and hudi-spark-client to differentiate them from each other",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1731"
          }
        }
      },
      {
        "issue": "HUDI-1737",
        "title": "Extract common method in HoodieCreateHandle & FlinkCreateHandle",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1737"
          }
        }
      },
      {
        "issue": "HUDI-1751",
        "title": "DeltaStream print many unnecessary warn log because of passing hoodie config to kafka consumer",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1751"
          }
        }
      },
      {
        "issue": "HUDI-1756",
        "title": "Assigns the buckets by record key for Flink writer",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1756"
          }
        }
      },
      {
        "issue": "HUDI-1757",
        "title": "Assigns the buckets by record key for Flink writer",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1757"
          }
        }
      },
      {
        "issue": "HUDI-1759",
        "title": "Save one connection retry when hiveSyncTool run with useJdbc=false",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1759"
          }
        }
      },
      {
        "issue": "HUDI-1764",
        "title": "Add support for Hudi CLI tools to schedule and run clustering",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1764"
          }
        }
      },
      {
        "issue": "HUDI-1767",
        "title": "Add setter to HoodieKey and HoodieRecordLocation to have better SE/DE performance for Flink",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1767"
          }
        }
      },
      {
        "issue": "HUDI-1773",
        "title": "HoodieFileGroup code optimize",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1773"
          }
        }
      },
      {
        "issue": "HUDI-1774",
        "title": "Add support or delete_partition with spark ds",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1774"
          }
        }
      },
      {
        "issue": "HUDI-1777",
        "title": "Add SparkDatasource support for delete_partition API",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1777"
          }
        }
      },
      {
        "issue": "HUDI-1778",
        "title": "Add setter to CompactionPlanEvent and CompactionCommitEvent to have better SE/DE performance for Flink",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1778"
          }
        }
      },
      {
        "issue": "HUDI-1784",
        "title": "Added print detailed stack log when hbase connection error",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1784"
          }
        }
      },
      {
        "issue": "HUDI-1785",
        "title": "Move OperationConverter to hudi-client-common for code reuse",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1785"
          }
        }
      },
      {
        "issue": "HUDI-1803",
        "title": "Support BAIDU AFS storage format in hudi",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1803"
          }
        }
      },
      {
        "issue": "HUDI-1812",
        "title": "Add explicit index state TTL option for Flink writer",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1812"
          }
        }
      },
      {
        "issue": "HUDI-1829",
        "title": "Use while loop instead of recursive call in MergeOnReadInputFormat to avoid StackOverflow",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1829"
          }
        }
      },
      {
        "issue": "HUDI-1837",
        "title": "Add optional instant range to log record scanner for log  block filtering",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1837"
          }
        }
      },
      {
        "issue": "HUDI-1841",
        "title": "Tweak the min max commits to keep when setting up cleaning retain commits for Flink",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1841"
          }
        }
      },
      {
        "issue": "HUDI-1844",
        "title": "Add option to flush when total buckets memory exceeds the threshold",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1844"
          }
        }
      },
      {
        "issue": "HUDI-1849",
        "title": "Remove the unit from the Flink sql options",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1849"
          }
        }
      },
      {
        "issue": "HUDI-1851",
        "title": "Automate suite of tests suites w/ docker and integ test",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1851"
          }
        }
      },
      {
        "issue": "HUDI-1857",
        "title": "Shade google guava for hudi-flink-bundle jar",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1857"
          }
        }
      },
      {
        "issue": "HUDI-1863",
        "title": "Add rate limiter to Flink writer to avoid OOM for bootstrap",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1863"
          }
        }
      },
      {
        "issue": "HUDI-1865",
        "title": "Make embedded time line service singleton",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1865"
          }
        }
      },
      {
        "issue": "HUDI-1867",
        "title": "Streaming read for Flink COW table",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1867"
          }
        }
      },
      {
        "issue": "HUDI-1874",
        "title": "Remove the broken file for FlinkMergeHandle",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1874"
          }
        }
      },
      {
        "issue": "HUDI-1878",
        "title": "Add max memory option for flink writer task",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1878"
          }
        }
      },
      {
        "issue": "HUDI-1880",
        "title": "Support streaming read with compaction and cleaning",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1880"
          }
        }
      },
      {
        "issue": "HUDI-1886",
        "title": "Avoid to generates corrupted files for flink sink",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1886"
          }
        }
      },
      {
        "issue": "HUDI-1895",
        "title": "Close the file handles gracefully for flink write function to avoid corrupted files",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1895"
          }
        }
      },
      {
        "issue": "HUDI-1900",
        "title": "Always close the file handle for a flink mini-batch write",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1900"
          }
        }
      },
      {
        "issue": "HUDI-1902",
        "title": "Clean the corrupted files generated by FlinkMergeAndReplaceHandle",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1902"
          }
        }
      },
      {
        "issue": "HUDI-1908",
        "title": "Global index for flink writer",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1908"
          }
        }
      },
      {
        "issue": "HUDI-1909",
        "title": "Skip the commits with empty files for flink streaming reader",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1909"
          }
        }
      },
      {
        "issue": "HUDI-1910",
        "title": "Supporting Kafka based checkpointing for HoodieDeltaStreamer",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1910"
          }
        }
      },
      {
        "issue": "HUDI-1911",
        "title": "Reuse the partition path and file group id for flink write data buffer",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1911"
          }
        }
      },
      {
        "issue": "HUDI-1913",
        "title": "Using streams instead of loops for readline",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1913"
          }
        }
      },
      {
        "issue": "HUDI-1920",
        "title": "Set \"archived\" as the default value of HOODIE_ARCHIVELOG_FOLDER_PROP_NAME",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1920"
          }
        }
      },
      {
        "issue": "HUDI-1921",
        "title": "Add target io option for flink compaction",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1921"
          }
        }
      },
      {
        "issue": "HUDI-1923",
        "title": "Add state in StreamWriteFunction to restore",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1923"
          }
        }
      },
      {
        "issue": "HUDI-1927",
        "title": "Improve HoodieFlinkStreamer",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1927"
          }
        }
      },
      {
        "issue": "HUDI-1931",
        "title": "BucketAssignFunction  use wrong state",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1931"
          }
        }
      },
      {
        "issue": "HUDI-1948",
        "title": "Shade kryo-shaded jar for hudi flink bundle",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1948"
          }
        }
      },
      {
        "issue": "HUDI-1949",
        "title": "Refactor BucketAssigner to make it more efficient",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1949"
          }
        }
      },
      {
        "issue": "HUDI-1952",
        "title": "Support hive3 meta sync for flink writer",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1952"
          }
        }
      },
      {
        "issue": "HUDI-1954",
        "title": "StreamWriterFunction only reset when flush success",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1954"
          }
        }
      },
      {
        "issue": "HUDI-1956",
        "title": "BucketAssignFunction use ValueState instead of MapState",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1956"
          }
        }
      },
      {
        "issue": "HUDI-1961",
        "title": "Add a debezium json integration test case for flink",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1961"
          }
        }
      },
      {
        "issue": "HUDI-1969",
        "title": "Support reading logs for MOR Hive rt table",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1969"
          }
        }
      },
      {
        "issue": "HUDI-1979",
        "title": " Optimize logic to improve code readability",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1979"
          }
        }
      },
      {
        "issue": "HUDI-1980",
        "title": "Optimize the code to prevent other exceptions from causing resources not to be closed",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1980"
          }
        }
      },
      {
        "issue": "HUDI-1984",
        "title": "Support independent flink hudi compaction function",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1984"
          }
        }
      },
      {
        "issue": "HUDI-1985",
        "title": "Website re-design implementation",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1985"
          }
        }
      },
      {
        "issue": "HUDI-1986",
        "title": "Skip creating marker files for flink merge handle",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1986"
          }
        }
      },
      {
        "issue": "HUDI-1992",
        "title": "Release the new records map for merge handle #close",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1992"
          }
        }
      },
      {
        "issue": "HUDI-1993",
        "title": "Add Baidu BOS storage support for hudi",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1993"
          }
        }
      },
      {
        "issue": "HUDI-1994",
        "title": "Release the new records iterator for append handle #close",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1994"
          }
        }
      },
      {
        "issue": "HUDI-2000",
        "title": "Release file writer for merge handle #close",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2000"
          }
        }
      },
      {
        "issue": "HUDI-2002",
        "title": "Modify the log level to ERROR",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2002"
          }
        }
      },
      {
        "issue": "HUDI-2004",
        "title": "Move KafkaOffsetGen.CheckpointUtils test cases to independent class and improve coverage",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2004"
          }
        }
      },
      {
        "issue": "HUDI-2006",
        "title": "Add more yamls to test suite",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2006"
          }
        }
      },
      {
        "issue": "HUDI-2007",
        "title": "Adding spark bulk insert node",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2007"
          }
        }
      },
      {
        "issue": "HUDI-2008",
        "title": "Add an annotation to suppress the compiler warnings",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2008"
          }
        }
      },
      {
        "issue": "HUDI-2014",
        "title": "Support flink hive sync in batch mode",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2014"
          }
        }
      },
      {
        "issue": "HUDI-2015",
        "title": "Fix flink operator uid to allow multiple pipelines in one job",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2015"
          }
        }
      },
      {
        "issue": "HUDI-2022",
        "title": "Release writer for append handle #close",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2022"
          }
        }
      },
      {
        "issue": "HUDI-2028",
        "title": "Implement RockDbBasedMap as an alternate to DiskBasedMap in SpillableMap",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2028"
          }
        }
      },
      {
        "issue": "HUDI-2029",
        "title": "Implement compression for DiskBasedMap in Spillable Map",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2029"
          }
        }
      },
      {
        "issue": "HUDI-2030",
        "title": "Add metadata cache to WriteProfile to reduce IO",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2030"
          }
        }
      },
      {
        "issue": "HUDI-2032",
        "title": "Make keygen class and keygen type optional for FlinkStreamerConfig",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2032"
          }
        }
      },
      {
        "issue": "HUDI-2036",
        "title": "Move the compaction plan scheduling out of flink writer coordinator",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2036"
          }
        }
      },
      {
        "issue": "HUDI-2037",
        "title": "Move the compaction plan scheduling out of flink writer coordinator",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2037"
          }
        }
      },
      {
        "issue": "HUDI-2038",
        "title": "Support rollback inflight compaction instances for CompactionPlanOperator",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2038"
          }
        }
      },
      {
        "issue": "HUDI-2040",
        "title": "Make flink writer as exactly-once by default",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2040"
          }
        }
      },
      {
        "issue": "HUDI-2042",
        "title": "Compare the field object directly in OverwriteWithLatestAvroPayload",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2042"
          }
        }
      },
      {
        "issue": "HUDI-2044",
        "title": "Extend support for rockDB and compression for Spillable map to all consumers of ExternalSpillableMap",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2044"
          }
        }
      },
      {
        "issue": "HUDI-2045",
        "title": "Support Read Hoodie As DataSource Table For Flink And DeltaStreamer",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2045"
          }
        }
      },
      {
        "issue": "HUDI-2047",
        "title": "Ignore FileNotFoundException in WriteProfiles #getWritePathsOfInstant",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2047"
          }
        }
      },
      {
        "issue": "HUDI-2050",
        "title": "Support rollback inflightCompactionInstance for batch flink compactor",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2050"
          }
        }
      },
      {
        "issue": "HUDI-2052",
        "title": "Support load logfile in BootstrapFunction",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2052"
          }
        }
      },
      {
        "issue": "HUDI-2054",
        "title": "Remove the duplicate name for flink write pipeline",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2054"
          }
        }
      },
      {
        "issue": "HUDI-2067",
        "title": "Sync all the options of FlinkOptions to FlinkStreamerConfig",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2067"
          }
        }
      },
      {
        "issue": "HUDI-2074",
        "title": "Use while loop instead of recursive call in MergeOnReadInputFormat#MergeIterator to avoid StackOverflow",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2074"
          }
        }
      },
      {
        "issue": "HUDI-2084",
        "title": "Resend the uncommitted write metadata when start up",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2084"
          }
        }
      },
      {
        "issue": "HUDI-2085",
        "title": "Support specify flink batch compaction paralleism and compaction target io",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2085"
          }
        }
      },
      {
        "issue": "HUDI-2087",
        "title": "Support Append only in Flink stream",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2087"
          }
        }
      },
      {
        "issue": "HUDI-2095",
        "title": "Scope out Append_only mode for hudi",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2095"
          }
        }
      },
      {
        "issue": "HUDI-2103",
        "title": "Add rebalance before index bootstrap",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2103"
          }
        }
      },
      {
        "issue": "HUDI-2112",
        "title": "Support reading pure logs file group for flink batch reader after compaction",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2112"
          }
        }
      },
      {
        "issue": "HUDI-2117",
        "title": "Unpersist the input rdd after the commit is completed",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2117"
          }
        }
      },
      {
        "issue": "HUDI-2121",
        "title": "Add operator uid for flink stateful operators",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2121"
          }
        }
      },
      {
        "issue": "HUDI-2122",
        "title": "Improvement in packaging insert into smallfiles",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2122"
          }
        }
      },
      {
        "issue": "HUDI-2126",
        "title": "The coordinator send events to write function when there are no data for the checkpoint",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2126"
          }
        }
      },
      {
        "issue": "HUDI-2132",
        "title": "Make coordinator events as POJO for efficient serialization",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2132"
          }
        }
      },
      {
        "issue": "HUDI-2133",
        "title": "Support hive1 metadata sync for flink writer",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2133"
          }
        }
      },
      {
        "issue": "HUDI-2134",
        "title": "Add generics to avoid forced conversion in BaseSparkCommitActionExecutor#partition",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2134"
          }
        }
      },
      {
        "issue": "HUDI-2135",
        "title": "Add compaction schedule option for flink",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2135"
          }
        }
      },
      {
        "issue": "HUDI-2142",
        "title": "Support setting bucket assign parallelism for flink write task",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2142"
          }
        }
      },
      {
        "issue": "HUDI-2143",
        "title": "Tweak the default compaction target IO to 500GB when flink async compaction is off",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2143"
          }
        }
      },
      {
        "issue": "HUDI-2145",
        "title": "Create new bucket when NewFileAssignState filled",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2145"
          }
        }
      },
      {
        "issue": "HUDI-2147",
        "title": "Remove unused class AvroConvertor in hudi-flink",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2147"
          }
        }
      },
      {
        "issue": "HUDI-2170",
        "title": "Always choose the latest record for HoodieRecordPayload",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2170"
          }
        }
      },
      {
        "issue": "HUDI-2171",
        "title": "Add parallelism conf for bootstrap operator",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2171"
          }
        }
      },
      {
        "issue": "HUDI-2184",
        "title": "Support setting hive sync partition extractor class based on flink configuration",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2184"
          }
        }
      },
      {
        "issue": "HUDI-2185",
        "title": "Remove the default parallelism of index bootstrap and bucket assigner",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2185"
          }
        }
      },
      {
        "issue": "HUDI-2192",
        "title": "Clean up Multiple versions of scala libraries detected Warning",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2192"
          }
        }
      },
      {
        "issue": "HUDI-2193",
        "title": "Remove state in BootstrapFunction",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2193"
          }
        }
      },
      {
        "issue": "HUDI-2198",
        "title": "Clean and reset the bootstrap events for coordinator when task failover",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2198"
          }
        }
      },
      {
        "issue": "HUDI-2204",
        "title": "Add marker files for flink writer",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2204"
          }
        }
      },
      {
        "issue": "HUDI-2205",
        "title": "Rollback inflight compaction for flink writer",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2205"
          }
        }
      },
      {
        "issue": "HUDI-2211",
        "title": "Fix NullPointerException in TestHoodieConsoleMetrics",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2211"
          }
        }
      },
      {
        "issue": "HUDI-2213",
        "title": "Remove unnecessary parameter for HoodieMetrics constructor and fix NPE in UT",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2213"
          }
        }
      },
      {
        "issue": "HUDI-2215",
        "title": "Add rateLimiter when Flink writes to hudi",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2215"
          }
        }
      },
      {
        "issue": "HUDI-2216",
        "title": "the words 'fiels' in the comments is incorrect",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2216"
          }
        }
      },
      {
        "issue": "HUDI-2228",
        "title": "Add option 'hive_sync.mode' for flink writer",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2228"
          }
        }
      },
      {
        "issue": "HUDI-2241",
        "title": "Explicit parallelism for flink bulk insert",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2241"
          }
        }
      },
      {
        "issue": "HUDI-2245",
        "title": "BucketAssigner generates the fileId evenly to avoid data skew",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2245"
          }
        }
      },
      {
        "issue": "HUDI-2247",
        "title": "Filter file where length less than parquet MAGIC length",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2247"
          }
        }
      },
      {
        "issue": "HUDI-2252",
        "title": "Default consumes from the latest instant for flink streaming reader",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2252"
          }
        }
      },
      {
        "issue": "HUDI-2254",
        "title": "Builtin sort operator for flink bulk insert",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2254"
          }
        }
      },
      {
        "issue": "HUDI-2255",
        "title": "Refactor DataSourceOptions",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2255"
          }
        }
      },
      {
        "issue": "HUDI-2256",
        "title": "Remove the while loop from BucketAssigner new bucket id algorithm",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2256"
          }
        }
      },
      {
        "issue": "HUDI-2272",
        "title": "Pass baseFileFormat to Meta Sync classes from DeltaSync",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2272"
          }
        }
      },
      {
        "issue": "HUDI-2273",
        "title": "Bring down the total test run time with CI",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2273"
          }
        }
      },
      {
        "issue": "HUDI-2278",
        "title": "Use INT64 timestamp with precision 3 for flink parquet writer",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2278"
          }
        }
      },
      {
        "issue": "HUDI-2279",
        "title": "Support column name matching for insert * and update set *  in merge into when sourceTable's columns contains all targetTable's columns",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2279"
          }
        }
      },
      {
        "issue": "HUDI-2288",
        "title": "support storage on ks3 for hudi",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2288"
          }
        }
      },
      {
        "issue": "HUDI-2293",
        "title": "Improve the Flink guide docs",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2293"
          }
        }
      },
      {
        "issue": "HUDI-2294",
        "title": "Add virtual key support to deltastreamer",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2294"
          }
        }
      },
      {
        "issue": "HUDI-2372",
        "title": "Fix tabs in spark quick start page esply around spark-sql",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2372"
          }
        }
      },
      {
        "issue": "HUDI-2373",
        "title": "Update website docs for 0.9.0 release",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2373"
          }
        }
      },
      {
        "issue": "HUDI-2382",
        "title": "Add release highlights for 090",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2382"
          }
        }
      },
      {
        "issue": "HUDI-2391",
        "title": "Fix release downloads page in accordance with ASF requirements",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2391"
          }
        }
      },
      {
        "issue": "HUDI-1714",
        "title": "Improve code coverage of TestHoodieTimelineArchiveLog",
        "type": "Test",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1714"
          }
        }
      },
      {
        "issue": "HUDI-2060",
        "title": "Create Tests for KafkaOffsetGen",
        "type": "Test",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2060"
          }
        }
      },
      {
        "issue": "HUDI-2113",
        "title": "Fix integration testing failure caused by sql results out of order",
        "type": "Test",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2113"
          }
        }
      },
      {
        "issue": "HUDI-2253",
        "title": "Reduce CI run time for deltastreamer and bulk insert row writer tests",
        "type": "Test",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2253"
          }
        }
      },
      {
        "issue": "HUDI-1742",
        "title": "improve table level config priority in HoodieMultiTableDeltaStreamer",
        "type": "Wish",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1742"
          }
        }
      },
      {
        "issue": "HUDI-637",
        "title": "Investigate slower hudi queries in S3 vs HDFS",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-637"
          }
        }
      },
      {
        "issue": "HUDI-1055",
        "title": "Ensure hardcoded storage type \".parquet\" is removed from tests",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1055"
          }
        }
      },
      {
        "issue": "HUDI-1277",
        "title": "[DOC] Need documentation explaining how to write custom record payload class",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1277"
          }
        }
      },
      {
        "issue": "HUDI-1495",
        "title": "Bump Flink version to 1.12.0",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1495"
          }
        }
      },
      {
        "issue": "HUDI-1518",
        "title": "Remove replaced files logic from archival",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1518"
          }
        }
      },
      {
        "issue": "HUDI-1775",
        "title": "Add option for compaction parallelism",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1775"
          }
        }
      },
      {
        "issue": "HUDI-1782",
        "title": "Add more options for HUDI Flink",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1782"
          }
        }
      },
      {
        "issue": "HUDI-1786",
        "title": "Add option for merge max memory",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1786"
          }
        }
      },
      {
        "issue": "HUDI-1787",
        "title": "Remove the rocksdb jar from hudi-flink-bundle",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1787"
          }
        }
      },
      {
        "issue": "HUDI-1788",
        "title": "Insert overwrite (table) for Flink writer",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1788"
          }
        }
      },
      {
        "issue": "HUDI-1791",
        "title": "Flush out all the write data buffer when Flink job crushes or cancels manually",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1791"
          }
        }
      },
      {
        "issue": "HUDI-1797",
        "title": "Shade google guava for hudi-flink-bundle jar",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1797"
          }
        }
      },
      {
        "issue": "HUDI-1819",
        "title": "Remove legacy code for Flink writer",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1819"
          }
        }
      },
      {
        "issue": "HUDI-1821",
        "title": "Remove legacy code for Flink writer",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1821"
          }
        }
      },
      {
        "issue": "HUDI-1836",
        "title": "Logging  consuming instant to StreamReadOperator#processSplits",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1836"
          }
        }
      },
      {
        "issue": "HUDI-1853",
        "title": "Add flink index and compaction options to document",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1853"
          }
        }
      },
      {
        "issue": "HUDI-1876",
        "title": "Wire in Hadoop conf to AvroSchemaConverters instantiation",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1876"
          }
        }
      },
      {
        "issue": "HUDI-1914",
        "title": "Add support to fetch latest table schema via hudi-cli",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1914"
          }
        }
      },
      {
        "issue": "HUDI-1929",
        "title": "Support configure KeyGenerator by type",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1929"
          }
        }
      },
      {
        "issue": "HUDI-1935",
        "title": "Update Logger for FlatteningTransformer",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1935"
          }
        }
      },
      {
        "issue": "HUDI-1940",
        "title": "Add SqlQueryBasedTransformer unit test",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1940"
          }
        }
      },
      {
        "issue": "HUDI-1991",
        "title": "Fix drop dups flow for bulk insert in row writer path",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-1991"
          }
        }
      },
      {
        "issue": "HUDI-2111",
        "title": "Update docs about bootstrap support configure KeyGenerator by type",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2111"
          }
        }
      },
      {
        "issue": "HUDI-2124",
        "title": "Grafana dashboard for HUDI",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2124"
          }
        }
      },
      {
        "issue": "HUDI-2164",
        "title": "Build cluster plan and execute this plan at once for HoodieClusteringJob",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2164"
          }
        }
      },
      {
        "issue": "HUDI-2168",
        "title": "AccessControlException for anonymous user",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2168"
          }
        }
      },
      {
        "issue": "HUDI-2194",
        "title": "Skip the latest N partitions when creating ClusteringPlan",
        "type": "Task",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HUDI/12350027"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HUDI-2194"
          }
        }
      }
    ]
  }
}