{
  "id": "12311021",
  "name": "0.4.0",
  "description": "",
  "date": "2006-06-28",
  "version": "0.4.0",
  "module": "",
  "lastUpdated": 1633087977986,
  "type": "release",
  "_links": {
    "self": {
      "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
    },
    "jira": {
      "href": "https://issues.apache.org/jira/browse/HADOOP/fixforversion/12311021"
    },
    "project": {
      "href": "https://apis.danklco.com/apache-release-info/HADOOP"
    }
  },
  "releaseNotes": "Release Notes - Hadoop Common - Version 0.4.0",
  "_embedded": {
    "issues": [
      {
        "issue": "HADOOP-27",
        "title": "MapRed tries to allocate tasks to nodes that have no available disk space",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-27"
          }
        }
      },
      {
        "issue": "HADOOP-32",
        "title": "Creating job with InputDir set to non-existant directory locks up jobtracker",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-32"
          }
        }
      },
      {
        "issue": "HADOOP-99",
        "title": "task trackers can only be assigned one task every heartbeat",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-99"
          }
        }
      },
      {
        "issue": "HADOOP-135",
        "title": "Potential deadlock in JobTracker.",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-135"
          }
        }
      },
      {
        "issue": "HADOOP-210",
        "title": "Namenode not able to accept connections",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-210"
          }
        }
      },
      {
        "issue": "HADOOP-244",
        "title": "very long cleanup after a job fails",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-244"
          }
        }
      },
      {
        "issue": "HADOOP-278",
        "title": "a missing map/reduce input directory does not produce a user-visible error message",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-278"
          }
        }
      },
      {
        "issue": "HADOOP-299",
        "title": "maps from second jobs will not run until the first job finishes completely",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-299"
          }
        }
      },
      {
        "issue": "HADOOP-304",
        "title": "UnregisteredDatanodeException message correction",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-304"
          }
        }
      },
      {
        "issue": "HADOOP-311",
        "title": "dfs client timeout on read kills task",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-311"
          }
        }
      },
      {
        "issue": "HADOOP-316",
        "title": "job tracker has a deadlock",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-316"
          }
        }
      },
      {
        "issue": "HADOOP-317",
        "title": "\"connection was forcibly closed\" Exception in RPC on Windows",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-317"
          }
        }
      },
      {
        "issue": "HADOOP-318",
        "title": "Progress in writing a DFS file does not count towards Job progress and can make the task timeout",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-318"
          }
        }
      },
      {
        "issue": "HADOOP-319",
        "title": "FileSystem \"close\" does not remove the closed fs from the fs map",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-319"
          }
        }
      },
      {
        "issue": "HADOOP-325",
        "title": "ClassNotFoundException under jvm 1.6",
        "type": "Bug",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-325"
          }
        }
      },
      {
        "issue": "HADOOP-123",
        "title": "mini map/reduce cluster for junit tests",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-123"
          }
        }
      },
      {
        "issue": "HADOOP-250",
        "title": "HTTP Browsing interface for DFS Health/Status",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-250"
          }
        }
      },
      {
        "issue": "HADOOP-296",
        "title": "Do not assign blocks to a datanode with < x mb free",
        "type": "New Feature",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-296"
          }
        }
      },
      {
        "issue": "HADOOP-59",
        "title": "support generic command-line options",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-59"
          }
        }
      },
      {
        "issue": "HADOOP-253",
        "title": "we need speculative execution for reduces",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-253"
          }
        }
      },
      {
        "issue": "HADOOP-257",
        "title": "starting one data node thread to manage multiple data directories",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-257"
          }
        }
      },
      {
        "issue": "HADOOP-271",
        "title": "add links to task tracker http server from task details and failure pages",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-271"
          }
        }
      },
      {
        "issue": "HADOOP-298",
        "title": "nicer reports of progress for distcp",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-298"
          }
        }
      },
      {
        "issue": "HADOOP-301",
        "title": "the randomwriter example will clobber the output file",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-301"
          }
        }
      },
      {
        "issue": "HADOOP-305",
        "title": "tasktracker waits for 10 seconds for asking for a task.",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-305"
          }
        }
      },
      {
        "issue": "HADOOP-314",
        "title": "remove the append phase in sorting the reduce inputs",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-314"
          }
        }
      },
      {
        "issue": "HADOOP-326",
        "title": "cleanup of dead field (map ouput port)",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-326"
          }
        }
      },
      {
        "issue": "HADOOP-328",
        "title": "add a -i option to distcp to ignore read errors of the input files",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-328"
          }
        }
      },
      {
        "issue": "HADOOP-336",
        "title": "The task tracker should track disk space used, and have a configurable cap",
        "type": "Improvement",
        "_links": {
          "release": {
            "href": "https://apis.danklco.com/apache-release-info/HADOOP/12311021"
          },
          "jira": {
            "href": "https://issues.apache.org/jira/browse/HADOOP-336"
          }
        }
      }
    ]
  }
}